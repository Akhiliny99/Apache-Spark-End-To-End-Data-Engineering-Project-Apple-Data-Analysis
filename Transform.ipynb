{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bdd4bc4-ff22-436f-b9e2-06eb90612371",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lead, col\n",
    "\n",
    "class Transformer:\n",
    "    def transform(self, inputDFs):\n",
    "        pass\n",
    "\n",
    "class FirstTransformer(Transformer):\n",
    "    def transform(self, inputDFs):\n",
    "        transaction_input_df = inputDFs.get(\"transaction_input_df\")\n",
    "        customer_input_df = inputDFs.get(\"customer_input_df\")  # Ensure correct key name\n",
    "\n",
    "        if transaction_input_df is None or customer_input_df is None:\n",
    "            print(\"Error: Required DataFrames not found in inputDFs\")\n",
    "            return None\n",
    "\n",
    "        print(\"Displaying transaction_input_df:\")\n",
    "        transaction_input_df.show()\n",
    "\n",
    "        print(\"Displaying customer_input_df:\")\n",
    "        customer_input_df.show()\n",
    "\n",
    "        # ‚úÖ Convert `customer_id` in transaction_input_df to match customer_input_df type (string)\n",
    "        transaction_input_df = transaction_input_df.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "\n",
    "        # Define Window Specification\n",
    "        windowSpec = Window.partitionBy(\"customer_id\").orderBy(\"transaction_date\")\n",
    "\n",
    "        # Apply lead function to get next product\n",
    "        transformedDF = transaction_input_df.withColumn(\n",
    "            \"next_product_name\", lead(\"product_name\").over(windowSpec)\n",
    "        )\n",
    "\n",
    "        print(\"Filtering: Customers who bought an iPhone and then AirPods\")\n",
    "        filteredDF = transformedDF.filter(\n",
    "            (transformedDF.product_name == \"iPhone\") & \n",
    "            (transformedDF.next_product_name == \"AirPods\")\n",
    "        )\n",
    "\n",
    "        # **Join with customer data on customer_id**\n",
    "        finalDF = filteredDF.join(customer_input_df, \"customer_id\", \"inner\") \\\n",
    "                            .select(\"customer_id\", \"customer_name\", \"join_date\", \"location\")\n",
    "\n",
    "        # Show results\n",
    "        finalDF.show()\n",
    "\n",
    "        # Additional Join Logic (if required)\n",
    "        joinDF = finalDF.join(customer_input_df, \"customer_id\")  # Joining finalDF with customer data again (if needed)\n",
    "        print(\"JOINDF\")\n",
    "        joinDF.show()\n",
    "\n",
    "        return joinDF  # Returning joinDF instead of finalDF if required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52835aeb-3690-4001-897d-abcab61ed8f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lead\n",
    "\n",
    "class Transformer:\n",
    "    def transform(self, inputDFs):\n",
    "        pass\n",
    "\n",
    "class FirstTransformer(Transformer):\n",
    "    def transform(self, inputDFs):\n",
    "        transaction_input_df = inputDFs.get(\"transaction_input_df\")\n",
    "        customer_input_df = inputDFs.get(\"customer_input_df\")  # Ensure correct key name\n",
    "\n",
    "        if transaction_input_df is None or customer_input_df is None:\n",
    "            print(\"Error: Required DataFrames not found in inputDFs\")\n",
    "            return None\n",
    "\n",
    "        print(\"Displaying transaction_input_df:\")\n",
    "        transaction_input_df.show()\n",
    "\n",
    "        print(\"Displaying customer_input_df:\")\n",
    "        customer_input_df.show()\n",
    "\n",
    "        # Define Window Specification\n",
    "        windowSpec = Window.partitionBy(\"customer_id\").orderBy(\"transaction_date\")\n",
    "\n",
    "        # Apply lead function to get next product\n",
    "        transformedDF = transaction_input_df.withColumn(\n",
    "            \"next_product_name\", lead(\"product_name\").over(windowSpec)\n",
    "        )\n",
    "\n",
    "        print(\"Filtering: Customers who bought an iPhone and then AirPods\")\n",
    "        filteredDF = transformedDF.filter(\n",
    "            (transformedDF.product_name == \"iPhone\") & \n",
    "            (transformedDF.next_product_name == \"AirPods\")\n",
    "        )\n",
    "\n",
    "        # **Join with customer data on customer_id**\n",
    "        finalDF = filteredDF.join(customer_input_df, \"customer_id\", \"inner\") \\\n",
    "                            .select(\"customer_id\", \"customer_name\", \"join_date\", \"location\")\n",
    "\n",
    "        # Show results\n",
    "        finalDF.show()\n",
    "\n",
    "        # Additional Join Logic (Fixed)\n",
    "        joinDF = finalDF.join(customer_input_df, \"customer_id\")  # Joining finalDF with customer data again (if needed)\n",
    "        print(\"JOINDF\")\n",
    "        joinDF.show()\n",
    "\n",
    "        return joinDF  # Returning joinDF instead of finalDF if required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac29bac9-5b73-4864-9f03-a7146a86828e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lead\n",
    "\n",
    "class Transformer:\n",
    "    def transform(self, inputDFs):\n",
    "        pass\n",
    "\n",
    "class FirstTransformer(Transformer):\n",
    "    def transform(self, inputDFs):\n",
    "        transaction_input_df = inputDFs.get(\"transaction_input_df\")\n",
    "\n",
    "        if transaction_input_df is None:\n",
    "            print(\"Error: 'transaction_input_df' not found in inputDFs\")\n",
    "            return None\n",
    "\n",
    "        print(\"Displaying transaction_input_df in transform:\")\n",
    "        transaction_input_df.show()\n",
    "\n",
    "        # Define Window Specification\n",
    "        windowSpec = Window.partitionBy(\"customer_id\").orderBy(\"transaction_date\")\n",
    "\n",
    "        # Apply Window Function\n",
    "        transformedDF = transaction_input_df.withColumn(\n",
    "            \"next_product_name\", lead(\"product_name\").over(windowSpec)\n",
    "        )\n",
    "\n",
    "        print(\"AirPods after buying iPhone\")\n",
    "        transformedDF.orderBy(\"customer_id\", \"transaction_date\", \"product_name\").show()\n",
    "\n",
    "        print(\"Filtering: Customers who bought an iPhone and then AirPods\")\n",
    "\n",
    "        # Filter only rows where product_name = 'iPhone' and next_product_name = 'AirPods'\n",
    "        filteredDF = transformedDF.filter(\n",
    "            (transformedDF.product_name == \"iPhone\") & \n",
    "            (transformedDF.next_product_name == \"AirPods\")\n",
    "        )\n",
    "\n",
    "        # Show results\n",
    "        filteredDF.show()\n",
    "\n",
    "        # Return the transformed DataFrame\n",
    "        return transformedDF\n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d5dd01c-5f41-4fa3-b264-c67a317801f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lead\n",
    "\n",
    "class Transformer:\n",
    "    def transform(self, inputDFs):\n",
    "        pass\n",
    "\n",
    "class FirstTransformer(Transformer):\n",
    "    def transform(self, inputDFs):\n",
    "        transaction_input_df = inputDFs.get(\"transaction_input_df\")\n",
    "        customer_df = inputDFs.get(\"customer_df\")  # Add customer data\n",
    "\n",
    "        if transaction_input_df is None or customer_df is None:\n",
    "            print(\"Error: Required DataFrames not found in inputDFs\")\n",
    "            return None\n",
    "\n",
    "        print(\"Displaying transaction_input_df:\")\n",
    "        transaction_input_df.show()\n",
    "\n",
    "        print(\"Displaying customer_df:\")\n",
    "        customer_df.show()\n",
    "\n",
    "        # Define Window Specification\n",
    "        windowSpec = Window.partitionBy(\"customer_id\").orderBy(\"transaction_date\")\n",
    "\n",
    "        # Apply lead function to get next product\n",
    "        transformedDF = transaction_input_df.withColumn(\n",
    "            \"next_product_name\", lead(\"product_name\").over(windowSpec)\n",
    "        )\n",
    "\n",
    "        print(\"Filtering: Customers who bought an iPhone and then AirPods\")\n",
    "        filteredDF = transformedDF.filter(\n",
    "            (transformedDF.product_name == \"iPhone\") & \n",
    "            (transformedDF.next_product_name == \"AirPods\")\n",
    "        )\n",
    "\n",
    "        # **Join with customer data on customer_id**\n",
    "        finalDF = filteredDF.join(customer_df, \"customer_id\", \"inner\") \\\n",
    "                            .select(\"customer_id\", \"customer_name\", \"join_date\", \"location\")\n",
    "\n",
    "        # Show results\n",
    "        finalDF.show()\n",
    "\n",
    "        return finalDF\n",
    "        customer_input_df = inputDFs.get(\"customer_input_df\")\n",
    "        joinDF = customer_input_df.join(customer_input_df,\"customer_id\")\n",
    "        print(\"JOINDF\")\n",
    "        joinDF.show()\n",
    "        return joinDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d00f58a5-12f0-4014-af81-af9f38ded908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lead\n",
    "\n",
    "class Transformer:\n",
    "    def transform(self, inputDFs):\n",
    "        pass\n",
    "\n",
    "class FirstTransformer(Transformer):\n",
    "    def transform(self, inputDFs):\n",
    "        transaction_input_df = inputDFs.get(\"transaction_input_df\")\n",
    "        customer_input_df = inputDFs.get(\"customer_input_df\")  # Fixed key\n",
    "\n",
    "        if transaction_input_df is None or customer_input_df is None:\n",
    "            print(\"‚ùå Error: Required DataFrames not found in inputDFs\")\n",
    "            return None\n",
    "\n",
    "        print(\"üìä Displaying transaction_input_df:\")\n",
    "        transaction_input_df.show()\n",
    "\n",
    "        print(\"üìä Displaying customer_input_df:\")\n",
    "        customer_input_df.show()\n",
    "\n",
    "        # Define Window Specification\n",
    "        windowSpec = Window.partitionBy(\"customer_id\").orderBy(\"transaction_date\")\n",
    "\n",
    "        # Apply lead function to get the next product\n",
    "        transformedDF = transaction_input_df.withColumn(\n",
    "            \"next_product_name\", lead(\"product_name\").over(windowSpec)\n",
    "        )\n",
    "\n",
    "        print(\"üîç Filtering: Customers who bought an iPhone and then AirPods\")\n",
    "        filteredDF = transformedDF.filter(\n",
    "            (transformedDF.product_name == \"iPhone\") & \n",
    "            (transformedDF.next_product_name == \"AirPods\")\n",
    "        )\n",
    "\n",
    "        # Perform the correct join\n",
    "        finalDF = self.joinDF(filteredDF, customer_input_df)\n",
    "\n",
    "        # Show final results\n",
    "        finalDF.show()\n",
    "\n",
    "        return finalDF\n",
    "\n",
    "    def joinDF(self, filteredDF, customer_input_df):\n",
    "        \"\"\"Performs an inner join between the filtered DataFrame and customer DataFrame\"\"\"\n",
    "        print(\"üîó Performing join operation...\")\n",
    "        joinDF = filteredDF.join(customer_input_df, \"customer_id\", \"inner\") \\\n",
    "                           .select(\"customer_id\", \"customer_name\", \"join_date\", \"location\")\n",
    "\n",
    "        print(\"‚úÖ Join operation completed. Displaying joinDF:\")\n",
    "        joinDF.show()\n",
    "        \n",
    "        return joinDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfbb9e84-7b99-4cc9-a0cb-898d9fca4bb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lead, col\n",
    "\n",
    "class Transformer:\n",
    "    def transform(self, inputDFs):\n",
    "        pass\n",
    "\n",
    "class FirstTransformer(Transformer):\n",
    "    def transform(self, inputDFs):\n",
    "        transaction_input_df = inputDFs.get(\"transaction_input_df\")\n",
    "        customer_input_df = inputDFs.get(\"customer_input_df\")  # Use consistent key name\n",
    "\n",
    "        if transaction_input_df is None or customer_input_df is None:\n",
    "            print(\"Error: Required DataFrames not found in inputDFs\")\n",
    "            return None\n",
    "\n",
    "        print(\"Displaying transaction_input_df:\")\n",
    "        transaction_input_df.show()\n",
    "\n",
    "        print(\"Displaying customer_input_df:\")\n",
    "        customer_input_df.show()\n",
    "\n",
    "        # ‚úÖ Convert `customer_id` in transaction_input_df to string for join compatibility\n",
    "        transaction_input_df = transaction_input_df.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "\n",
    "        # Define Window Specification\n",
    "        windowSpec = Window.partitionBy(\"customer_id\").orderBy(\"transaction_date\")\n",
    "\n",
    "        # Apply lead function to get next product\n",
    "        transformedDF = transaction_input_df.withColumn(\n",
    "            \"next_product_name\", lead(\"product_name\").over(windowSpec)\n",
    "        )\n",
    "\n",
    "        print(\"Filtering: Customers who bought an iPhone and then AirPods\")\n",
    "        filteredDF = transformedDF.filter(\n",
    "            (transformedDF.product_name == \"iPhone\") & \n",
    "            (transformedDF.next_product_name == \"AirPods\")\n",
    "        )\n",
    "\n",
    "        # ‚úÖ Join with customer data on customer_id\n",
    "        finalDF = filteredDF.join(customer_input_df, \"customer_id\", \"inner\") \\\n",
    "                            .select(\"customer_id\", \"customer_name\", \"join_date\", \"location\")\n",
    "\n",
    "        print(\"Final transformed DataFrame:\")\n",
    "        finalDF.show()\n",
    "\n",
    "        return finalDF  # ‚úÖ Removed dead code after return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af6bb6c-5914-459e-bd7f-26f7d8cd483c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lead, col\n",
    "\n",
    "class Transformer:\n",
    "    def transform(self, inputDFs):\n",
    "        pass\n",
    "\n",
    "class FirstTransformer(Transformer):\n",
    "    def transform(self, inputDFs):\n",
    "        transaction_input_df = inputDFs.get(\"transaction_input_df\")\n",
    "        customer_input_df = inputDFs.get(\"customer_input_df\")  # Use correct key\n",
    "\n",
    "        if transaction_input_df is None or customer_input_df is None:\n",
    "            print(\"Error: Required DataFrames not found in inputDFs\")\n",
    "            return None\n",
    "\n",
    "        print(\"Displaying transaction_input_df:\")\n",
    "        transaction_input_df.show()\n",
    "\n",
    "        print(\"Displaying customer_input_df:\")\n",
    "        customer_input_df.show()\n",
    "\n",
    "        # ‚úÖ Ensure `customer_id` has the same type in both DataFrames\n",
    "        transaction_input_df = transaction_input_df.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "        customer_input_df = customer_input_df.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "\n",
    "        # Define Window Specification\n",
    "        windowSpec = Window.partitionBy(\"customer_id\").orderBy(\"transaction_date\")\n",
    "\n",
    "        # Apply lead function to get next product\n",
    "        transformedDF = transaction_input_df.withColumn(\n",
    "            \"next_product_name\", lead(\"product_name\").over(windowSpec)\n",
    "        )\n",
    "\n",
    "        print(\"Filtering: Customers who bought an iPhone and then AirPods\")\n",
    "        filteredDF = transformedDF.filter(\n",
    "            (transformedDF.product_name == \"iPhone\") & \n",
    "            (transformedDF.next_product_name == \"AirPods\")\n",
    "        )\n",
    "\n",
    "        # ‚úÖ Perform Join with customer data on `customer_id`\n",
    "        finalDF = filteredDF.join(customer_input_df, \"customer_id\", \"inner\") \\\n",
    "                            .select(\"customer_id\", \"customer_name\", \"join_date\", \"location\")\n",
    "\n",
    "        print(\"Final Transformed DataFrame:\")\n",
    "        finalDF.show()\n",
    "\n",
    "        return finalDF\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Transform",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
